{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GP Model 2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMN81lcuihNaPEpmdppMJ8h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"POQpUq40q8k5","executionInfo":{"status":"ok","timestamp":1619619745337,"user_tz":-120,"elapsed":8825,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}},"outputId":"927045be-4986-4939-91a2-01b2fcda3915"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import keras\n","import tensorflow as tf\n","from keras.models import Model, Sequential\n","from keras.layers import Dense, Embedding, Input,  Activation\n","from keras.layers import  LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras import initializers, optimizers, layers\n","from sklearn.metrics import roc_auc_score\n","from keras.models import Sequential\n","from keras.initializers import Constant\n","from keras.callbacks import ModelCheckpoint\n","from keras.models import load_model\n","import pandas as pd\n","import io \n","import re                                  # library for regular expression operations\n","import string \n","!pip install emoji                             # for string operations\n","import emoji\n","from nltk.corpus import stopwords          # module for stop words that come with NLTK\n","from nltk.stem import PorterStemmer        # module for stemming\n","from nltk.tokenize import regexp_tokenize   # module for tokenizing strings\n","from nltk.tokenize import TreebankWordTokenizer\n","import nltk \n","import numpy as np\n","!pip install WordCloud\n","from wordcloud import WordCloud, STOPWORDS\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from tensorflow.python.keras.utils import layer_utils\n","from keras import backend as K\n","from keras.engine.topology import Layer\n","from keras import initializers, regularizers, constraints\n","from keras.models import Sequential"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting emoji\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/fa/b3368f41b95a286f8d300e323449ab4e86b85334c2e0b477e94422b8ed0f/emoji-1.2.0-py3-none-any.whl (131kB)\n","\r\u001b[K     |██▌                             | 10kB 18.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 19.3MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 30kB 15.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 51kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 61kB 10.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 71kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 81kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 92kB 10.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 102kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 112kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 122kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 8.9MB/s \n","\u001b[?25hInstalling collected packages: emoji\n","Successfully installed emoji-1.2.0\n","Requirement already satisfied: WordCloud in /usr/local/lib/python3.7/dist-packages (1.5.0)\n","Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from WordCloud) (1.19.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from WordCloud) (7.1.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qi1Q54KvtV9h","executionInfo":{"status":"ok","timestamp":1619620279868,"user_tz":-120,"elapsed":893,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}},"outputId":"c46c4ac7-e820-4eec-81a6-63ca34e339f3"},"source":["import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"zKq9SfCjqAkT","executionInfo":{"status":"ok","timestamp":1619620280271,"user_tz":-120,"elapsed":559,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}},"outputId":"613bc42d-f7ec-4172-a1ff-027d8faeaa5c"},"source":["train_df = pd.read_csv(\"SmallTwitter.csv\")# twitter comments\n","train_df.head()"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>@user when a father is dysfunctional and is s...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>@user @user thanks for #lyft credit i can't us...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>bihday your majesty</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>#model   i love u take with u all the time in ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>factsguide: society now    #motivation</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  label                                              tweet\n","0   1      0   @user when a father is dysfunctional and is s...\n","1   2      0  @user @user thanks for #lyft credit i can't us...\n","2   3      0                                bihday your majesty\n","3   4      0  #model   i love u take with u all the time in ...\n","4   5      0             factsguide: society now    #motivation"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"RgvB2kbWqWKh"},"source":["# Clean Data\n"]},{"cell_type":"markdown","metadata":{"id":"Z7kn7vX4ox-y"},"source":["###Remove @ username in Twitter"]},{"cell_type":"code","metadata":{"id":"6hOGd94tsL8n","executionInfo":{"status":"ok","timestamp":1619620283833,"user_tz":-120,"elapsed":1084,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["def remove_at_user(text):\n","\n","  \"\"\"\n","      Remove @username from tweets\n","  \"\"\"\n","  \n","  return re.sub(\"@[A-Za-z0-9]+\",\"\",text)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"hjhj4Vv5tSzj","executionInfo":{"status":"ok","timestamp":1619620284889,"user_tz":-120,"elapsed":1035,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["train_df[\"text_clean\"] = train_df[\"tweet\"].apply(lambda x: remove_at_user(x))"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9b1XThQboDLi"},"source":["###  Contractions \n","\n","We use the contractions package to expand the contraction in English such as we'll -> we will or we shouldn't've -> we should not have."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SdIiCz30q_c0","executionInfo":{"status":"ok","timestamp":1619620278965,"user_tz":-120,"elapsed":6699,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}},"outputId":"37ba9179-53d7-487b-c250-39ea72a09fc4"},"source":["!pip install contractions\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Collecting contractions\n","  Downloading https://files.pythonhosted.org/packages/0a/04/d5e0bb9f2cef5d15616ebf68087a725c5dbdd71bd422bcfb35d709f98ce7/contractions-0.0.48-py2.py3-none-any.whl\n","Collecting textsearch>=0.0.21\n","  Downloading https://files.pythonhosted.org/packages/d3/fe/021d7d76961b5ceb9f8d022c4138461d83beff36c3938dc424586085e559/textsearch-0.0.21-py2.py3-none-any.whl\n","Collecting pyahocorasick\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/c2/eae730037ae1cbbfaa229d27030d1d5e34a1e41114b21447d1202ae9c220/pyahocorasick-1.4.2.tar.gz (321kB)\n","\u001b[K     |████████████████████████████████| 327kB 7.5MB/s \n","\u001b[?25hCollecting anyascii\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/14/666cd44bf53f36a961544af592cb5c5c800013f9c51a4745af8d7c17362a/anyascii-0.2.0-py3-none-any.whl (283kB)\n","\u001b[K     |████████████████████████████████| 286kB 13.7MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n","  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85392 sha256=a6dbdbc24371086a76d64df31e492e988feda4cbc4ff8024fa17208027c1d8df\n","  Stored in directory: /root/.cache/pip/wheels/3a/03/34/77e3ece0bba8b86bfac88a79f923b36d805cad63caeba38842\n","Successfully built pyahocorasick\n","Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n","Successfully installed anyascii-0.2.0 contractions-0.0.48 pyahocorasick-1.4.2 textsearch-0.0.21\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Kx5ic9egrlK-","executionInfo":{"status":"ok","timestamp":1619620288229,"user_tz":-120,"elapsed":999,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["import contractions\n","train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: contractions.fix(x))"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QHdZgf8Sgoi5"},"source":["### Repeat the captial words \n","Here we repeat the Captial words to confirm the meaning of this word as the user try to focus on it\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":262},"id":"l8zIkM2igy5i","executionInfo":{"status":"ok","timestamp":1619620311841,"user_tz":-120,"elapsed":6239,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}},"outputId":"341c64df-121a-43da-d2d5-467455f8d9c8"},"source":["!pip install nltk\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","train_df['tokenized'] = train_df[\"text_clean\"].apply(word_tokenize)\n","train_df.head()\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>tweet</th>\n","      <th>text_clean</th>\n","      <th>tokenized</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>@user when a father is dysfunctional and is s...</td>\n","      <td>when a father is dysfunctional and is so sel...</td>\n","      <td>[when, a, father, is, dysfunctional, and, is, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>@user @user thanks for #lyft credit i can't us...</td>\n","      <td>thanks for #lyft credit i can not use becaus...</td>\n","      <td>[thanks, for, #, lyft, credit, i, can, not, us...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>bihday your majesty</td>\n","      <td>bihday your majesty</td>\n","      <td>[bihday, your, majesty]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>#model   i love u take with u all the time in ...</td>\n","      <td>#model   i love you take with you all the time...</td>\n","      <td>[#, model, i, love, you, take, with, you, all,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>factsguide: society now    #motivation</td>\n","      <td>factsguide: society now    #motivation</td>\n","      <td>[factsguide, :, society, now, #, motivation]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  ...                                          tokenized\n","0   1  ...  [when, a, father, is, dysfunctional, and, is, ...\n","1   2  ...  [thanks, for, #, lyft, credit, i, can, not, us...\n","2   3  ...                            [bihday, your, majesty]\n","3   4  ...  [#, model, i, love, you, take, with, you, all,...\n","4   5  ...       [factsguide, :, society, now, #, motivation]\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"f7BqLRrIIaoa","executionInfo":{"status":"ok","timestamp":1619620316876,"user_tz":-120,"elapsed":540,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["train_df['text_clean']=train_df['tokenized'].apply(lambda x:  [word  if word.isupper() == False else word+\" \"+word  for word in x]) \n","train_df['text_clean'] = [' '.join(map(str, l)) for l in train_df['text_clean']] # join back to text"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"XSid1k5Tl267","executionInfo":{"status":"ok","timestamp":1619620318809,"user_tz":-120,"elapsed":651,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}},"outputId":"8085ec33-38c4-476b-9906-9e381b2a2257"},"source":["\n","train_df.head()"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>tweet</th>\n","      <th>text_clean</th>\n","      <th>tokenized</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>@user when a father is dysfunctional and is s...</td>\n","      <td>when a father is dysfunctional and is so selfi...</td>\n","      <td>[when, a, father, is, dysfunctional, and, is, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>@user @user thanks for #lyft credit i can't us...</td>\n","      <td>thanks for # lyft credit i can not use because...</td>\n","      <td>[thanks, for, #, lyft, credit, i, can, not, us...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>bihday your majesty</td>\n","      <td>bihday your majesty</td>\n","      <td>[bihday, your, majesty]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>#model   i love u take with u all the time in ...</td>\n","      <td># model i love you take with you all the time ...</td>\n","      <td>[#, model, i, love, you, take, with, you, all,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>factsguide: society now    #motivation</td>\n","      <td>factsguide : society now # motivation</td>\n","      <td>[factsguide, :, society, now, #, motivation]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  ...                                          tokenized\n","0   1  ...  [when, a, father, is, dysfunctional, and, is, ...\n","1   2  ...  [thanks, for, #, lyft, credit, i, can, not, us...\n","2   3  ...                            [bihday, your, majesty]\n","3   4  ...  [#, model, i, love, you, take, with, you, all,...\n","4   5  ...       [factsguide, :, society, now, #, motivation]\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"jdh6w0c9gzki"},"source":["###  Covert to lower case"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"auI4cFbvqbCY","executionInfo":{"status":"ok","timestamp":1619620329692,"user_tz":-120,"elapsed":630,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}},"outputId":"6396d1be-f841-4628-c7ab-35f50ecad83a"},"source":["train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: x.lower())\n","display(train_df.head())"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>tweet</th>\n","      <th>text_clean</th>\n","      <th>tokenized</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>@user when a father is dysfunctional and is s...</td>\n","      <td>when a father is dysfunctional and is so selfi...</td>\n","      <td>[when, a, father, is, dysfunctional, and, is, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>@user @user thanks for #lyft credit i can't us...</td>\n","      <td>thanks for # lyft credit i can not use because...</td>\n","      <td>[thanks, for, #, lyft, credit, i, can, not, us...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>bihday your majesty</td>\n","      <td>bihday your majesty</td>\n","      <td>[bihday, your, majesty]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>#model   i love u take with u all the time in ...</td>\n","      <td># model i love you take with you all the time ...</td>\n","      <td>[#, model, i, love, you, take, with, you, all,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>factsguide: society now    #motivation</td>\n","      <td>factsguide : society now # motivation</td>\n","      <td>[factsguide, :, society, now, #, motivation]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  ...                                          tokenized\n","0   1  ...  [when, a, father, is, dysfunctional, and, is, ...\n","1   2  ...  [thanks, for, #, lyft, credit, i, can, not, us...\n","2   3  ...                            [bihday, your, majesty]\n","3   4  ...  [#, model, i, love, you, take, with, you, all,...\n","4   5  ...       [factsguide, :, society, now, #, motivation]\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"yvy5NH5CojyJ"},"source":["### Remove any URLS"]},{"cell_type":"code","metadata":{"id":"uIHYHjOtrMIc","executionInfo":{"status":"ok","timestamp":1619620331515,"user_tz":-120,"elapsed":577,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["def remove_URL(text):\n","    \"\"\"\n","        Remove URLs from a sample string\n","    \"\"\"\n","\n","    return re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"m3d4iMiNrPn0","executionInfo":{"status":"ok","timestamp":1619620333894,"user_tz":-120,"elapsed":566,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_URL(x))"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DFejSgwJos7I"},"source":["### Remove HTML Tages"]},{"cell_type":"code","metadata":{"id":"w-DOPNF2r27r","executionInfo":{"status":"ok","timestamp":1619620335610,"user_tz":-120,"elapsed":526,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["def remove_html(text):\n","    \"\"\"\n","        Remove the html in sample text\n","    \"\"\"\n","    html = re.compile(r\"<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});\")\n","    return re.sub(html, \"\", text)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"sH3wQ3Emr5vP","executionInfo":{"status":"ok","timestamp":1619620337511,"user_tz":-120,"elapsed":937,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_html(x))"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B1Weuyiwo9NE"},"source":["### Replace the Typos, slang, acronyms or informal abbreviations"]},{"cell_type":"code","metadata":{"id":"qQwTF4UWvFuq","executionInfo":{"status":"ok","timestamp":1619620359061,"user_tz":-120,"elapsed":970,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["def informalAbbreviations_clean(text):\n","        \"\"\"\n","            Other manual text cleaning techniques\n","        \"\"\"\n","        # Typos, slang and other\n","        sample_typos_slang = {\n","                                \"w/e\": \"whatever\",\n","                                \"usagov\": \"usa government\",\n","                                \"recentlu\": \"recently\",\n","                                \"ph0tos\": \"photos\",\n","                                \"amirite\": \"am i right\",\n","                                \"exp0sed\": \"exposed\",\n","                                \"<3\": \"love\",\n","                                \"luv\": \"love\",\n","                                \"amageddon\": \"armageddon\",\n","                                \"trfc\": \"traffic\",\n","                                \"16yr\": \"16 year\"\n","                                }\n","\n","        # Acronyms\n","        sample_acronyms =  { \n","                            \"mh370\": \"malaysia airlines flight 370\",\n","                            \"okwx\": \"oklahoma city weather\",\n","                            \"arwx\": \"arkansas weather\",    \n","                            \"gawx\": \"georgia weather\",  \n","                            \"scwx\": \"south carolina weather\",  \n","                            \"cawx\": \"california weather\",\n","                            \"tnwx\": \"tennessee weather\",\n","                            \"azwx\": \"arizona weather\",  \n","                            \"alwx\": \"alabama weather\",\n","                            \"usnwsgov\": \"united states national weather service\",\n","                            \"2mw\": \"tomorrow\"\n","                            }\n","\n","        \n","        # Some common abbreviations \n","        sample_abbr = {\n","                        \"$\" : \" dollar \",\n","                        \"€\" : \" euro \",\n","                        \"4ao\" : \"for adults only\",\n","                        \"a.m\" : \"before midday\",\n","                        \"a3\" : \"anytime anywhere anyplace\",\n","                        \"aamof\" : \"as a matter of fact\",\n","                        \"acct\" : \"account\",\n","                        \"adih\" : \"another day in hell\",\n","                        \"afaic\" : \"as far as i am concerned\",\n","                        \"afaict\" : \"as far as i can tell\",\n","                        \"afaik\" : \"as far as i know\",\n","                        \"afair\" : \"as far as i remember\",\n","                        \"afk\" : \"away from keyboard\",\n","                        \"app\" : \"application\",\n","                        \"approx\" : \"approximately\",\n","                        \"apps\" : \"applications\",\n","                        \"asap\" : \"as soon as possible\",\n","                        \"asl\" : \"age, sex, location\",\n","                        \"atk\" : \"at the keyboard\",\n","                        \"ave.\" : \"avenue\",\n","                        \"aymm\" : \"are you my mother\",\n","                        \"ayor\" : \"at your own risk\", \n","                        \"b&b\" : \"bed and breakfast\",\n","                        \"b+b\" : \"bed and breakfast\",\n","                        \"b.c\" : \"before christ\",\n","                        \"b2b\" : \"business to business\",\n","                        \"b2c\" : \"business to customer\",\n","                        \"b4\" : \"before\",\n","                        \"b4n\" : \"bye for now\",\n","                        \"b@u\" : \"back at you\",\n","                        \"bae\" : \"before anyone else\",\n","                        \"bak\" : \"back at keyboard\",\n","                        \"bbbg\" : \"bye bye be good\",\n","                        \"bbc\" : \"british broadcasting corporation\",\n","                        \"bbias\" : \"be back in a second\",\n","                        \"bbl\" : \"be back later\",\n","                        \"bbs\" : \"be back soon\",\n","                        \"be4\" : \"before\",\n","                        \"bfn\" : \"bye for now\",\n","                        \"blvd\" : \"boulevard\",\n","                        \"bout\" : \"about\",\n","                        \"brb\" : \"be right back\",\n","                        \"bros\" : \"brothers\",\n","                        \"brt\" : \"be right there\",\n","                        \"bsaaw\" : \"big smile and a wink\",\n","                        \"btw\" : \"by the way\",\n","                        \"bwl\" : \"bursting with laughter\",\n","                        \"c/o\" : \"care of\",\n","                        \"cet\" : \"central european time\",\n","                        \"cf\" : \"compare\",\n","                        \"cia\" : \"central intelligence agency\",\n","                        \"csl\" : \"can not stop laughing\",\n","                        \"cu\" : \"see you\",\n","                        \"cul8r\" : \"see you later\",\n","                        \"cv\" : \"curriculum vitae\",\n","                        \"cwot\" : \"complete waste of time\",\n","                        \"cya\" : \"see you\",\n","                        \"cyt\" : \"see you tomorrow\",\n","                        \"dae\" : \"does anyone else\",\n","                        \"dbmib\" : \"do not bother me i am busy\",\n","                        \"diy\" : \"do it yourself\",\n","                        \"dm\" : \"direct message\",\n","                        \"dwh\" : \"during work hours\",\n","                        \"e123\" : \"easy as one two three\",\n","                        \"eet\" : \"eastern european time\",\n","                        \"eg\" : \"example\",\n","                        \"embm\" : \"early morning business meeting\",\n","                        \"encl\" : \"enclosed\",\n","                        \"encl.\" : \"enclosed\",\n","                        \"etc\" : \"and so on\",\n","                        \"faq\" : \"frequently asked questions\",\n","                        \"fawc\" : \"for anyone who cares\",\n","                        \"fb\" : \"facebook\",\n","                        \"fc\" : \"fingers crossed\",\n","                        \"fig\" : \"figure\",\n","                        \"fimh\" : \"forever in my heart\", \n","                        \"ft.\" : \"feet\",\n","                        \"ft\" : \"featuring\",\n","                        \"ftl\" : \"for the loss\",\n","                        \"ftw\" : \"for the win\",\n","                        \"fwiw\" : \"for what it is worth\",\n","                        \"fyi\" : \"for your information\",\n","                        \"g9\" : \"genius\",\n","                        \"gahoy\" : \"get a hold of yourself\",\n","                        \"gal\" : \"get a life\",\n","                        \"gcse\" : \"general certificate of secondary education\",\n","                        \"gfn\" : \"gone for now\",\n","                        \"gg\" : \"good game\",\n","                        \"gl\" : \"good luck\",\n","                        \"glhf\" : \"good luck have fun\",\n","                        \"gmt\" : \"greenwich mean time\",\n","                        \"gmta\" : \"great minds think alike\",\n","                        \"gn\" : \"good night\",\n","                        \"g.o.a.t\" : \"greatest of all time\",\n","                        \"goat\" : \"greatest of all time\",\n","                        \"goi\" : \"get over it\",\n","                        \"gps\" : \"global positioning system\",\n","                        \"gr8\" : \"great\",\n","                        \"gratz\" : \"congratulations\",\n","                        \"gyal\" : \"girl\",\n","                        \"h&c\" : \"hot and cold\",\n","                        \"hp\" : \"horsepower\",\n","                        \"hr\" : \"hour\",\n","                        \"hrh\" : \"his royal highness\",\n","                        \"ht\" : \"height\",\n","                        \"ibrb\" : \"i will be right back\",\n","                        \"ic\" : \"i see\",\n","                        \"icq\" : \"i seek you\",\n","                        \"icymi\" : \"in case you missed it\",\n","                        \"idc\" : \"i do not care\",\n","                        \"idgadf\" : \"i do not give a damn fuck\",\n","                        \"idgaf\" : \"i do not give a fuck\",\n","                        \"idk\" : \"i do not know\",\n","                        \"ie\" : \"that is\",\n","                        \"i.e\" : \"that is\",\n","                        \"ifyp\" : \"i feel your pain\",\n","                        \"IG\" : \"instagram\",\n","                        \"iirc\" : \"if i remember correctly\",\n","                        \"ilu\" : \"i love you\",\n","                        \"ily\" : \"i love you\",\n","                        \"imho\" : \"in my humble opinion\",\n","                        \"imo\" : \"in my opinion\",\n","                        \"imu\" : \"i miss you\",\n","                        \"iow\" : \"in other words\",\n","                        \"irl\" : \"in real life\",\n","                        \"j4f\" : \"just for fun\",\n","                        \"jic\" : \"just in case\",\n","                        \"jk\" : \"just kidding\",\n","                        \"jsyk\" : \"just so you know\",\n","                        \"l8r\" : \"later\",\n","                        \"lb\" : \"pound\",\n","                        \"lbs\" : \"pounds\",\n","                        \"ldr\" : \"long distance relationship\",\n","                        \"lmao\" : \"laugh my ass off\",\n","                        \"lmfao\" : \"laugh my fucking ass off\",\n","                        \"lol\" : \"laughing out loud\",\n","                        \"ltd\" : \"limited\",\n","                        \"ltns\" : \"long time no see\",\n","                        \"m8\" : \"mate\",\n","                        \"mf\" : \"motherfucker\",\n","                        \"mfs\" : \"motherfuckers\",\n","                        \"mfw\" : \"my face when\",\n","                        \"mofo\" : \"motherfucker\",\n","                        \"mph\" : \"miles per hour\",\n","                        \"mr\" : \"mister\",\n","                        \"mrw\" : \"my reaction when\",\n","                        \"ms\" : \"miss\",\n","                        \"mte\" : \"my thoughts exactly\",\n","                        \"nagi\" : \"not a good idea\",\n","                        \"nbc\" : \"national broadcasting company\",\n","                        \"nbd\" : \"not big deal\",\n","                        \"nfs\" : \"not for sale\",\n","                        \"ngl\" : \"not going to lie\",\n","                        \"nhs\" : \"national health service\",\n","                        \"nrn\" : \"no reply necessary\",\n","                        \"nsfl\" : \"not safe for life\",\n","                        \"nsfw\" : \"not safe for work\",\n","                        \"nth\" : \"nice to have\",\n","                        \"nvr\" : \"never\",\n","                        \"nyc\" : \"new york city\",\n","                        \"oc\" : \"original content\",\n","                        \"og\" : \"original\",\n","                        \"ohp\" : \"overhead projector\",\n","                        \"oic\" : \"oh i see\",\n","                        \"omdb\" : \"over my dead body\",\n","                        \"omg\" : \"oh my god\",\n","                        \"omw\" : \"on my way\",\n","                        \"p.a\" : \"per annum\",\n","                        \"p.m\" : \"after midday\",\n","                        \"pm\" : \"prime minister\",\n","                        \"poc\" : \"people of color\",\n","                        \"pov\" : \"point of view\",\n","                        \"pp\" : \"pages\",\n","                        \"ppl\" : \"people\",\n","                        \"prw\" : \"parents are watching\",\n","                        \"ps\" : \"postscript\",\n","                        \"pt\" : \"point\",\n","                        \"ptb\" : \"please text back\",\n","                        \"pto\" : \"please turn over\",\n","                        \"qpsa\" : \"what happens\", #\"que pasa\",\n","                        \"ratchet\" : \"rude\",\n","                        \"rbtl\" : \"read between the lines\",\n","                        \"rlrt\" : \"real life retweet\", \n","                        \"rofl\" : \"rolling on the floor laughing\",\n","                        \"roflol\" : \"rolling on the floor laughing out loud\",\n","                        \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n","                        \"rt\" : \"retweet\",\n","                        \"ruok\" : \"are you ok\",\n","                        \"sfw\" : \"safe for work\",\n","                        \"sk8\" : \"skate\",\n","                        \"smh\" : \"shake my head\",\n","                        \"sq\" : \"square\",\n","                        \"srsly\" : \"seriously\", \n","                        \"ssdd\" : \"same stuff different day\",\n","                        \"tbh\" : \"to be honest\",\n","                        \"tbs\" : \"tablespooful\",\n","                        \"tbsp\" : \"tablespooful\",\n","                        \"tfw\" : \"that feeling when\",\n","                        \"thks\" : \"thank you\",\n","                        \"tho\" : \"though\",\n","                        \"thx\" : \"thank you\",\n","                        \"tia\" : \"thanks in advance\",\n","                        \"til\" : \"today i learned\",\n","                        \"tl;dr\" : \"too long i did not read\",\n","                        \"tldr\" : \"too long i did not read\",\n","                        \"tmb\" : \"tweet me back\",\n","                        \"tntl\" : \"trying not to laugh\",\n","                        \"ttyl\" : \"talk to you later\",\n","                        \"u\" : \"you\",\n","                        \"u2\" : \"you too\",\n","                        \"u4e\" : \"yours for ever\",\n","                        \"utc\" : \"coordinated universal time\",\n","                        \"w/\" : \"with\",\n","                        \"w/o\" : \"without\",\n","                        \"w8\" : \"wait\",\n","                        \"wassup\" : \"what is up\",\n","                        \"wb\" : \"welcome back\",\n","                        \"wtf\" : \"what the fuck\",\n","                        \"wtg\" : \"way to go\",\n","                        \"wtpa\" : \"where the party at\",\n","                        \"wuf\" : \"where are you from\",\n","                        \"wuzup\" : \"what is up\",\n","                        \"wywh\" : \"wish you were here\",\n","                        \"yd\" : \"yard\",\n","                        \"ygtr\" : \"you got that right\",\n","                        \"ynk\" : \"you never know\",\n","                        \"zzz\" : \"sleeping bored and tired\"\n","                        }\n","            \n","        sample_typos_slang_pattern = re.compile(r'(?<!\\w)(' + '|'.join(re.escape(key) for key in sample_typos_slang.keys()) + r')(?!\\w)')\n","        sample_acronyms_pattern = re.compile(r'(?<!\\w)(' + '|'.join(re.escape(key) for key in sample_acronyms.keys()) + r')(?!\\w)')\n","        sample_abbr_pattern = re.compile(r'(?<!\\w)(' + '|'.join(re.escape(key) for key in sample_abbr.keys()) + r')(?!\\w)')\n","        \n","        text = sample_typos_slang_pattern.sub(lambda x: sample_typos_slang[x.group()], text)\n","        text = sample_acronyms_pattern.sub(lambda x: sample_acronyms[x.group()], text)\n","        text = sample_abbr_pattern.sub(lambda x: sample_abbr[x.group()], text)\n","        \n","        return text"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"XinQSdMDz4eD","executionInfo":{"status":"ok","timestamp":1619620376290,"user_tz":-120,"elapsed":4109,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: informalAbbreviations_clean(x))"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"8I5fJ73U5e3_","executionInfo":{"status":"ok","timestamp":1619620395147,"user_tz":-120,"elapsed":680,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}},"outputId":"dc095914-e7a8-4f43-c1d1-11cf4dbd8fbf"},"source":["display(train_df.head())"],"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>tweet</th>\n","      <th>text_clean</th>\n","      <th>tokenized</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>@user when a father is dysfunctional and is s...</td>\n","      <td>when a father is dysfunctional and is so selfi...</td>\n","      <td>[when, a, father, is, dysfunctional, and, is, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>@user @user thanks for #lyft credit i can't us...</td>\n","      <td>thanks for # lyft credit i can not use because...</td>\n","      <td>[thanks, for, #, lyft, credit, i, can, not, us...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>bihday your majesty</td>\n","      <td>bihday your majesty</td>\n","      <td>[bihday, your, majesty]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>#model   i love u take with u all the time in ...</td>\n","      <td># model i love you take with you all the time ...</td>\n","      <td>[#, model, i, love, you, take, with, you, all,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>factsguide: society now    #motivation</td>\n","      <td>factsguide : society now # motivation</td>\n","      <td>[factsguide, :, society, now, #, motivation]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  ...                                          tokenized\n","0   1  ...  [when, a, father, is, dysfunctional, and, is, ...\n","1   2  ...  [thanks, for, #, lyft, credit, i, can, not, us...\n","2   3  ...                            [bihday, your, majesty]\n","3   4  ...  [#, model, i, love, you, take, with, you, all,...\n","4   5  ...       [factsguide, :, society, now, #, motivation]\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lo81m5fbNdod","executionInfo":{"status":"ok","timestamp":1619620525956,"user_tz":-120,"elapsed":3248,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}},"outputId":"260814b3-7448-447e-8acd-225cc10ba577"},"source":["!pip install autocorrect\n","from autocorrect import Speller "],"execution_count":37,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: autocorrect in /usr/local/lib/python3.7/dist-packages (2.5.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KZ37br_Zpozn"},"source":["### Spelling Correction"]},{"cell_type":"code","metadata":{"id":"QH_NcAUu1PGW","executionInfo":{"status":"ok","timestamp":1619620529656,"user_tz":-120,"elapsed":1069,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["def spelling_correction(text):\n","  \"\"\"\n","    Here apply Textblob to correct the spelling\n","  \"\"\"\n","  repeat_pattern = re.compile(r'(\\w)\\1*')\n","  match_substitution = r'\\1'\n","  new_word = repeat_pattern.sub(match_substitution,text)\n","  spell = Speller(lang='en')  \n","  return spell(new_word)"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"iCyIBdbI1JjV","executionInfo":{"status":"ok","timestamp":1619623589887,"user_tz":-120,"elapsed":3057467,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: spelling_correction(x))"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"opCDZtQZNceY","executionInfo":{"status":"ok","timestamp":1619625895404,"user_tz":-120,"elapsed":560,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["  dict_emot= { ':-)'  : b'\\xf0\\x9f\\x98\\x8a'.decode('utf-8'),\n","                ':)'   : b'\\xf0\\x9f\\x98\\x8a'.decode('utf-8'),\n","                '=)'   : b'\\xf0\\x9f\\x98\\x8a'.decode('utf-8'),  # Smile or happy\n","                ':-D'  : b'\\xf0\\x9f\\x98\\x83'.decode('utf-8'),\n","                ':D'   : b'\\xf0\\x9f\\x98\\x83'.decode('utf-8'),\n","                '=D'   : b'\\xf0\\x9f\\x98\\x83'.decode('utf-8'),  # Big smile\n","                '>:-(' : b'\\xF0\\x9F\\x98\\xA0'.decode('utf-8'),\n","                ':@'   : b'\\xF0\\x9F\\x98\\xA0'.decode('utf-8')   # Angry face\n","                }"],"execution_count":50,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GetVuAwTr7rJ"},"source":["### Converting some emojis text to emojis"]},{"cell_type":"code","metadata":{"id":"9RTfSzbKhbx5","executionInfo":{"status":"ok","timestamp":1619625441233,"user_tz":-120,"elapsed":719,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["\n","# def emojiTransalte(Text):\n","\n","#   dict_emot= { ':-)'  : b'\\xf0\\x9f\\x98\\x8a'.decode('utf-8'),\n","#                 ':)'   : b'\\xf0\\x9f\\x98\\x8a'.decode('utf-8'),\n","#                 '=)'   : b'\\xf0\\x9f\\x98\\x8a'.decode('utf-8'),  # Smile or happy\n","#                 ':-D'  : b'\\xf0\\x9f\\x98\\x83'.decode('utf-8'),\n","#                 ':D'   : b'\\xf0\\x9f\\x98\\x83'.decode('utf-8'),\n","#                 '=D'   : b'\\xf0\\x9f\\x98\\x83'.decode('utf-8'),  # Big smile\n","#                 '>:-(' : b'\\xF0\\x9F\\x98\\xA0'.decode('utf-8'),\n","#                 ':@'   : b'\\xF0\\x9F\\x98\\xA0'.decode('utf-8')   # Angry face\n","#                 }\n","#   return dict_emot[text]"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gww7gT_PgHE0"},"source":["# train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: emojiTransalte(x))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lQptCVO3sHbH"},"source":["### Remove non ascii charcters"]},{"cell_type":"code","metadata":{"id":"hWVtKJQOr9gX","executionInfo":{"status":"ok","timestamp":1619626859315,"user_tz":-120,"elapsed":1308,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["def remove_non_ascii(text):\n","\n","    \"\"\"\n","        Remove non-ASCII characters \n","    \"\"\"\n","\n","    return re.sub(r'[^\\x00-\\x7f]',r'', text) "],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"12PeMtcer9qS","executionInfo":{"status":"ok","timestamp":1619626860219,"user_tz":-120,"elapsed":1022,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_non_ascii(x))"],"execution_count":52,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kDA5QDoKsN9c"},"source":["### Remove any other special characters"]},{"cell_type":"code","metadata":{"id":"aK4HiF1ctyaM","executionInfo":{"status":"ok","timestamp":1619626863014,"user_tz":-120,"elapsed":2502,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["def remove_special_characters(text):\n","    \"\"\"\n","        Remove special special characters, including symbols, emojis, and other graphic characters\n","    \"\"\"\n","    emoji_pattern = re.compile(\n","        '['\n","        u'\\U0001F600-\\U0001F64F'  # emoticons\n","        u'\\U0001F300-\\U0001F5FF'  # symbols & pictographs\n","        u'\\U0001F680-\\U0001F6FF'  # transport & map symbols\n","        u'\\U0001F1E0-\\U0001F1FF'  # flags (iOS)\n","        u'\\U00002702-\\U000027B0'\n","        u'\\U000024C2-\\U0001F251'\n","        ']+',\n","        flags=re.UNICODE)\n","    return emoji_pattern.sub(r'', text)"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"jJ-nIi9lt4q9","executionInfo":{"status":"ok","timestamp":1619626863494,"user_tz":-120,"elapsed":1625,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_special_characters(x))"],"execution_count":54,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DdFa7rJ4scmX"},"source":["### Remove punctuation"]},{"cell_type":"code","metadata":{"id":"Cd5lpBLMt7gF","executionInfo":{"status":"ok","timestamp":1619626866096,"user_tz":-120,"elapsed":1555,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["def remove_punct(text):\n","    \"\"\"\n","        Remove the punctuation\n","    \"\"\"\n","    return text.translate(str.maketrans('', '', string.punctuation))"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q3ba7b_qvC_y","executionInfo":{"status":"ok","timestamp":1619626867907,"user_tz":-120,"elapsed":1840,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["train_df[\"text_clean\"] = train_df[\"text_clean\"].apply(lambda x: remove_punct(x))"],"execution_count":57,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YfOjDB_lhZRL"},"source":["\n","# Text Preprocessing\n"]},{"cell_type":"markdown","metadata":{"id":"1bAT3-7Xtw7_"},"source":["### **Tokenization**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":229},"id":"NSlKvw5IhYAp","executionInfo":{"status":"ok","timestamp":1619626875438,"user_tz":-120,"elapsed":6757,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}},"outputId":"8090d39d-5e13-46b3-ac54-f66adfeecc4c"},"source":["!pip install nltk\n","from nltk.tokenize import word_tokenize\n","\n","train_df[\"tokenized\"] = train_df[\"text_clean\"].apply(word_tokenize)\n","train_df.head()"],"execution_count":58,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>tweet</th>\n","      <th>text_clean</th>\n","      <th>tokenized</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>@user when a father is dysfunctional and is s...</td>\n","      <td>when a father is dysfunctional and is so selfi...</td>\n","      <td>[when, a, father, is, dysfunctional, and, is, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>@user @user thanks for #lyft credit i can't us...</td>\n","      <td>thanks for  left credit i can not use because ...</td>\n","      <td>[thanks, for, left, credit, i, can, not, use, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>bihday your majesty</td>\n","      <td>birthday your majesty</td>\n","      <td>[birthday, your, majesty]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>#model   i love u take with u all the time in ...</td>\n","      <td>model i love you take with you al the time in...</td>\n","      <td>[model, i, love, you, take, with, you, al, the...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>factsguide: society now    #motivation</td>\n","      <td>factsguide  society now  motivation</td>\n","      <td>[factsguide, society, now, motivation]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  ...                                          tokenized\n","0   1  ...  [when, a, father, is, dysfunctional, and, is, ...\n","1   2  ...  [thanks, for, left, credit, i, can, not, use, ...\n","2   3  ...                          [birthday, your, majesty]\n","3   4  ...  [model, i, love, you, take, with, you, al, the...\n","4   5  ...             [factsguide, society, now, motivation]\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"markdown","metadata":{"id":"iHM4_fkLhOE9"},"source":["\n","### **Remove stop word**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S57840OahNVx","executionInfo":{"status":"ok","timestamp":1619626875440,"user_tz":-120,"elapsed":5513,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}},"outputId":"4d701115-3cdd-4d33-9925-226ef06cc5a6"},"source":["nltk.download(\"stopwords\")\n","from nltk.corpus import stopwords\n","\n","stop = set(stopwords.words('english'))\n","train_df['stopwords_removed'] = train_df[\"tokenized\"].apply(lambda x: [word for word in x if word not in stop])"],"execution_count":59,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QEAsIAOmjplO"},"source":["### **Part of Speech Tagging (POS Tagging):**\n","\n","Part of speech tagging (POS tagging) distinguishes the part of speech (noun, verb, adjective, and etc.) of each word in the text."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X93d9jNBjpKw","executionInfo":{"status":"ok","timestamp":1619626947181,"user_tz":-120,"elapsed":3023,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}},"outputId":"80332ff3-0c61-488a-94e1-7691eb4b7554"},"source":["import nltk\n","nltk.download('wordnet')\n","nltk.download('brown')\n","from nltk.corpus import wordnet\n","from nltk.corpus import brown\n","\n","wordnet_map = {\"N\":wordnet.NOUN, \n","               \"V\":wordnet.VERB, \n","               \"J\":wordnet.ADJ, \n","               \"R\":wordnet.ADV\n","              }\n","    \n","train_sents = brown.tagged_sents(categories='news')\n","t0 = nltk.DefaultTagger('NN')\n","t1 = nltk.UnigramTagger(train_sents, backoff=t0)\n","t2 = nltk.BigramTagger(train_sents, backoff=t1)\n","\n","def pos_tag_wordnet(text, pos_tag_type=\"pos_tag\"):\n","    \"\"\"\n","        Create pos_tag with wordnet format\n","    \"\"\"\n","    pos_tagged_text = t2.tag(text)\n","    \n","    # map the pos tagging output with wordnet output \n","    pos_tagged_text = [(word, wordnet_map.get(pos_tag[0])) if pos_tag[0] in wordnet_map.keys() else (word, wordnet.NOUN) for (word, pos_tag) in pos_tagged_text ]\n","    return pos_tagged_text"],"execution_count":64,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/brown.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PsxJo-ZMjzed","executionInfo":{"status":"ok","timestamp":1619626951367,"user_tz":-120,"elapsed":997,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["train_df['pos_tag'] = train_df['stopwords_removed'].apply(lambda x: pos_tag_wordnet(x))"],"execution_count":65,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ovWC2bDEj8BS"},"source":["### **Lemmatization:**\n","\n","Lemmatization is the task of determining that two words have the same root, despite their surface differences. The words am, are, and is have the shared lemma be; the words dinner and dinners both have the lemma dinner. \n","Lemmatizing each of these forms to the same lemma will let us ﬁnd all mentions of words in Russian like Moscow."]},{"cell_type":"code","metadata":{"id":"21FBhMGsS0t1","executionInfo":{"status":"ok","timestamp":1619627038857,"user_tz":-120,"elapsed":678,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["from nltk.stem import WordNetLemmatizer\n","\n","def lemmatize_word(text):\n","    \"\"\"\n","        Lemmatize the tokenized words\n","    \"\"\"\n","\n","    lemmatizer = WordNetLemmatizer()\n","    lemma = [lemmatizer.lemmatize(word, tag) for word, tag in text]\n","    return lemma"],"execution_count":68,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y-AQijDVkNRs","executionInfo":{"status":"ok","timestamp":1619627042829,"user_tz":-120,"elapsed":2807,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","\n","train_df['lemmatize_word_w_pos'] = train_df['pos_tag'].apply(lambda x: lemmatize_word(x))\n","train_df['lemmatize_word_w_pos'] = train_df['lemmatize_word_w_pos'].apply(lambda x: [word for word in x if word not in stop]) # double check to remove stop words\n","train_df['lemmatize_text'] = [' '.join(map(str, l)) for l in train_df['lemmatize_word_w_pos']] # join back to text"],"execution_count":69,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9UtI18Fft6pA"},"source":["### **Saving Dataset**"]},{"cell_type":"code","metadata":{"id":"oPgGeR4j9NKz","executionInfo":{"status":"ok","timestamp":1619627057070,"user_tz":-120,"elapsed":1317,"user":{"displayName":"Nancy Hassan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjfzroUWqthIy7jUUOd9jfaIhO9mtFnKpf8FI7FpQ=s64","userId":"08005434482666482410"}}},"source":["train_df.to_csv('cleanSmallTwitter.csv')"],"execution_count":70,"outputs":[]}]}